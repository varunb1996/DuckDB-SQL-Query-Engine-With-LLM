This project shows how to use DuckDB as a backend for AI applications by combining vector storage, SQL querying, and language models. It demonstrates two main capabilities:

Using DuckDB as a vector database in a Retrieval-Augmented Generation (RAG) pipeline (e.g. with LlamaIndex) to index embeddings and retrieve context for LLM queries

Turning DuckDB into a conversational SQL query engine, so that users can ask natural language questions about structured data and the system internally generates SQL, executes it, and returns results in readable form
